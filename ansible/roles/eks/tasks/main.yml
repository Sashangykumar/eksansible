---
- name: Create VPC
  amazon.aws.ec2_vpc_net:
    name: "{{ cluster_name }}-vpc"
    cidr_block: "{{ vpc_cidr }}"
    region: "{{ region }}"
    tags:
      Environment: "{{ cluster_name }}"
    state: present
  register: vpc

- name: Create Internet Gateway
  amazon.aws.ec2_vpc_igw:
    vpc_id: "{{ vpc.vpc.id }}"
    region: "{{ region }}"
    tags:
      Name: "{{ cluster_name }}-igw"
    state: present
  register: igw

- name: Create public subnets
  amazon.aws.ec2_vpc_subnet:
    vpc_id: "{{ vpc.vpc.id }}"
    cidr: "{{ item.cidr }}"
    region: "{{ region }}"
    az: "{{ region }}{{ item.az }}"
    map_public: true
    tags:
      Name: "{{ cluster_name }}-public-{{ item.az }}"
      kubernetes.io/role/elb: "1"
    state: present
  loop:
    - { cidr: "{{ public_subnet_cidrs[0] }}", az: "a" }
    - { cidr: "{{ public_subnet_cidrs[1] }}", az: "b" }
  register: public_subnets

- name: Create private subnets
  amazon.aws.ec2_vpc_subnet:
    vpc_id: "{{ vpc.vpc.id }}"
    cidr: "{{ item.cidr }}"
    region: "{{ region }}"
    az: "{{ region }}{{ item.az }}"
    tags:
      Name: "{{ cluster_name }}-private-{{ item.az }}"
      kubernetes.io/role/internal-elb: "1"
    state: present
  loop:
    - { cidr: "{{ private_subnet_cidrs[0] }}", az: "a" }
    - { cidr: "{{ private_subnet_cidrs[1] }}", az: "b" }
  register: private_subnets

- name: Create route table for public subnets
  amazon.aws.ec2_vpc_route_table:
    vpc_id: "{{ vpc.vpc.id }}"
    region: "{{ region }}"
    tags:
      Name: "{{ cluster_name }}-public-rt"
    subnets:
      - "{{ public_subnets.results[0].subnet.id }}"
      - "{{ public_subnets.results[1].subnet.id }}"
    routes:
      - dest: "0.0.0.0/0"
        gateway_id: "{{ igw.gateway_id }}"

# ------------------------------------------------------------------------------
# IAM Roles
# ------------------------------------------------------------------------------

- name: Create EKS cluster service role
  amazon.aws.iam_role:
    name: "{{ cluster_name }}-cluster-role"
    assume_role_policy_document: |
      {
        "Version": "2012-10-17",
        "Statement": [
          {
            "Effect": "Allow",
            "Principal": { "Service": "eks.amazonaws.com" },
            "Action": "sts:AssumeRole"
          }
        ]
      }
    managed_policies:
      - arn:aws:iam::aws:policy/AmazonEKSClusterPolicy
      - arn:aws:iam::aws:policy/AmazonEKSServicePolicy  # üîπ FIX: Added missing EKS service policy
    state: present

- name: Create EKS node group service role
  amazon.aws.iam_role:
    name: "{{ cluster_name }}-node-role"
    assume_role_policy_document: |
      {
        "Version": "2012-10-17",
        "Statement": [
          {
            "Effect": "Allow",
            "Principal": { "Service": "ec2.amazonaws.com" },
            "Action": "sts:AssumeRole"
          }
        ]
      }
    managed_policies:
      - arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy
      - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy
      - arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly
    state: present

- name: Create EKS service-linked role
  shell: aws iam create-service-linked-role --aws-service-name eks.amazonaws.com
  register: slr_result
  failed_when:
    - slr_result.rc != 0
    - "'has been taken' not in slr_result.stderr"

- name: Wait for IAM role propagation
  pause:
    seconds: 90

# ------------------------------------------------------------------------------
# Cluster Creation
# ------------------------------------------------------------------------------

- name: Test AWS permissions
  shell: aws eks list-clusters --region {{ region }}
  register: permission_test

- name: Create EKS cluster
  command: >
    aws eks create-cluster
    --name {{ cluster_name }}
    --version {{ kubernetes_version }}
    --role-arn arn:aws:iam::{{ ansible_account_id }}:role/{{ cluster_name }}-cluster-role
    --resources-vpc-config subnetIds={{ public_subnets.results[0].subnet.id }},{{ public_subnets.results[1].subnet.id }},{{ private_subnets.results[0].subnet.id }},{{ private_subnets.results[1].subnet.id }}
    --region {{ region }}
    --output json
  register: cluster_result
  failed_when:
    - cluster_result.rc != 0
    - "'ResourceInUseException' not in cluster_result.stderr"

- name: Wait 60 seconds for cluster to register
  pause:
    seconds: 60

# üîπ FIX: Replaced invalid ‚Äústdout check‚Äù with AWS describe-cluster validation
- name: Verify EKS cluster exists
  shell: aws eks describe-cluster --name {{ cluster_name }} --region {{ region }} --output json
  register: describe_result
  retries: 10
  delay: 30
  until: describe_result.rc == 0
  failed_when:
    - describe_result.rc != 0
    - "'ResourceNotFoundException' in describe_result.stderr"

# üîπ FIX: Added retryable cluster-active wait
- name: Wait for EKS cluster to be active
  shell: aws eks wait cluster-active --name {{ cluster_name }} --region {{ region }}
  register: cluster_active
  retries: 5
  delay: 60
  failed_when:
    - cluster_active.rc != 0

# ------------------------------------------------------------------------------
# Node Group
# ------------------------------------------------------------------------------

- name: Create EKS node group
  shell: |
    aws eks create-nodegroup \
      --cluster-name {{ cluster_name }} \
      --nodegroup-name {{ node_group_name }} \
      --node-role arn:aws:iam::{{ ansible_account_id }}:role/{{ cluster_name }}-node-role \
      --subnets {{ private_subnets.results[0].subnet.id }} {{ private_subnets.results[1].subnet.id }} \
      --instance-types {{ node_instance_type }} \
      --scaling-config minSize={{ node_min_size }},maxSize={{ node_max_size }},desiredSize={{ node_desired_capacity }} \
      --region {{ region }}
  register: nodegroup_result
  failed_when:
    - nodegroup_result.rc != 0
    - "'ResourceInUseException' not in nodegroup_result.stderr"

- name: Wait for node group to be active
  shell: aws eks wait nodegroup-active --cluster-name {{ cluster_name }} --nodegroup-name {{ node_group_name }} --region {{ region }}
  retries: 5
  delay: 60

# ------------------------------------------------------------------------------
# Kubeconfig + Output
# ------------------------------------------------------------------------------

- name: Generate kubeconfig
  shell: aws eks update-kubeconfig --region {{ region }} --name {{ cluster_name }}

- name: Get cluster information
  shell: aws eks describe-cluster --name {{ cluster_name }} --region {{ region }} --query 'cluster.{arn:arn,endpoint:endpoint}' --output json
  register: cluster_info

- name: Display cluster information
  debug:
    msg:
      - "EKS Cluster: {{ cluster_name }}"
      - "Region: {{ region }}"
      - "Status: Active"
      - "Cluster Info: {{ cluster_info.stdout | from_json }}"
